# Sync layer – Step 1

## Idempotency rule

Каждый dataset обязан иметь естественный ключ идемпотентности.
Все данные, полученные из API, должны сохраняться через UPSERT.

Повторная синхронизация одного и того же периода:
- не должна создавать дубликаты
- не должна ломать агрегаты
- должна быть безопасна

Checkpoint обновляется ТОЛЬКО после успешного применения данных в БД.

## Архитектура

### DatasetKey

Определяет, какие типы данных синхронизируются:
- `sales` — продажи
- `returns` — возвраты
- `logistics` — логистика
- `penalties` — штрафы
- `advCosts` — расходы на рекламу
- `storageCosts` — расходы на хранение
- `acceptanceCosts` — расходы на приёмку
- `productOrders` — заказы товаров
- `supplies` — поставки

### Checkpoint

Хранит прогресс синхронизации для каждого dataset:
- `cursorTime` — до какого момента данные гарантированно загружены
- `cursorToken` — для постраничных API (pageToken / cursor / offset)
- `highWatermarkTime` — верхняя стабильная граница (например: "вчера 23:59")
- `updatedAt` — когда checkpoint был обновлён

### CheckpointRepository

Абстракция для хранения чекпоинтов. Реализация будет добавлена на следующих шагах.

## Правила

1. **Идемпотентность**: Повторная синхронизация одного периода не создаёт дубликаты
2. **Атомарность**: Checkpoint обновляется только после успешного применения данных
3. **Расширяемость**: Новые dataset добавляются через расширение типа `DatasetKey`

## Smart Policy (priority/catchup/refresh)

### Стратегии синхронизации

Система использует три режима синхронизации:

#### Priority (приоритетная загрузка)
- **Назначение**: Быстрый старт приложения для UI
- **Поведение**: Загружает последние N дней (настраивается через `priorityDays` в `DatasetPolicy`)
- **Когда используется**: При старте приложения, когда нужно быстро показать актуальные данные
- **Режим**: Использует `mode='refresh'` для перезагрузки данных

#### Catchup (догон истории)
- **Назначение**: Постепенная загрузка исторических данных в фоне
- **Поведение**: Загружает данные чанками (настраивается через `catchupChunkDays`)
- **Логика**: Начинает с `checkpoint.cursorTime` и загружает следующий чанк до `highWatermark`
- **Ограничения**: 
  - Учитывает `maxHistoryDays` (не загружает данные старше N дней)
  - Ограничивается `maxCatchupRunsPerTick` в оркестраторе
- **Когда используется**: В фоновом режиме, после завершения priority wave

#### Refresh (обновление плавающих данных)
- **Назначение**: Перезагрузка недавних данных, которые могут изменяться ретроспективно
- **Поведение**: Загружает последние N дней с overlap (настраивается через `refreshOverlapDays`)
- **Когда используется**: Периодически (настраивается через `refreshEveryMinutes`)
- **Примеры**: Данные о логистике, штрафах могут обновляться ретроспективно

#### Backfill (загрузка истории назад)
- **Назначение**: Загрузка исторических данных, когда история отсутствует или неполная
- **Поведение**: Загружает данные назад по времени от последней закрытой недели до нижней границы
- **Логика**: 
  - Движется **назад** по времени (в отличие от catchup, который движется вперёд)
  - Для sales: загружает строго по **полным неделям** (Пн–Вс) в режиме `weekly`
  - Использует отдельный checkpoint (`sales_backfill`) для отслеживания прогресса
  - Останавливается на `backfillLowerBound` (по умолчанию: '2024-01-29')
- **Когда используется**: 
  - Только если история отсутствует или неполная
  - Работает независимо от catchup (не мешает ему)
  - Выполняется в фоновом режиме через `runBackfillTick()`
- **Отличия от catchup**:
  - Catchup движется **вперёд** от checkpoint до highWatermark
  - Backfill движется **назад** от последней закрытой недели до lowerBound
  - Catchup использует daily режим, backfill использует weekly режим (для sales)
  - Catchup и backfill используют разные checkpoint keys

### Почему highWatermark = "вчера"?

`highWatermark` устанавливается на "вчера" (через `defaultHighWatermark()`), чтобы:
1. **Избежать нестабильности**: Сегодняшний день ещё формируется, данные могут изменяться
2. **Предсказуемость**: Граница синхронизации стабильна в течение дня
3. **Надёжность**: Исключаем риски с частичными данными текущего дня

### Почему нужен catchup chunking?

Чанкинг (разбиение на части) в catchup необходим для:
1. **Лимиты API**: Избегаем превышения лимитов запросов и таймаутов
2. **Производительность**: Не блокируем UI длительными операциями
3. **Надёжность**: При ошибке теряется только один чанк, а не вся история
4. **Прогресс**: Можно отслеживать прогресс по чанкам и возобновлять с места остановки

## Orchestrator Waves

`SyncOrchestrator` автоматически управляет синхронизацией через "волны":

### Priority Wave (`runPriorityWave`)
- Запускается при старте приложения
- Загружает приоритетные datasets (`priorityDatasets`)
- Быстрая загрузка для немедленного отображения в UI

### Catchup Tick (`runCatchupTick`)
- Запускается в фоне после priority wave
- Постепенно догоняет историю для `historyDatasets`
- Ограничивается `maxCatchupRunsPerTick` за один тик
- Возвращает количество выполненных запусков для мониторинга прогресса

### Refresh Wave (`runRefreshWave`)
- Периодически обновляет плавающие данные
- Использует `refreshOverlapDays` для перезагрузки недавних данных
- Работает с приоритетными datasets

### Backfill Tick (`runBackfillTick`)
- Загружает историю назад по полным неделям (для sales)
- Работает только если `policy.backfillEnabled === true`
- Использует отдельный checkpoint (`sales_backfill`) для отслеживания прогресса
- Возвращает прогресс выполнения: `{ runs, completed, progress }`
- Выполняет максимум 1 неделю за тик
- Останавливается автоматически, когда достигает `backfillLowerBound`

### Конфигурация

Настройка происходит через `OrchestratorOptions`:
- `priorityDatasets`: Список datasets для быстрой загрузки при старте
- `historyDatasets`: Список datasets для фонового догона истории
- `maxCatchupRunsPerTick`: Максимальное количество запусков catchup за один тик

### Пример использования

```typescript
const orchestrator = new SyncOrchestrator(
  ctx,
  runner,
  defaultSyncPolicy,
  {
    priorityDatasets: ['sales', 'returns', 'advCosts'],
    historyDatasets: ['sales', 'returns', 'logistics', 'penalties', 'advCosts'],
    maxCatchupRunsPerTick: 5,
  }
)

// При старте приложения
await orchestrator.runPriorityWave()

// В фоне
const { runs } = await orchestrator.runCatchupTick()

// Периодически
await orchestrator.runRefreshWave()

// Backfill (если история отсутствует)
const backfillResult = await orchestrator.runBackfillTick()
if (backfillResult.completed) {
  console.log('Backfill завершён:', backfillResult.progress.percent + '%')
}
```

## Smart calendar logic (daily vs weekly)

Для dataset `sales` реализована календарно-осознанная логика загрузки:

### Daily режим
- Используется для **текущей (неполной) недели**
- Загружает данные по дням с пагинацией
- Обновляется регулярно через refresh wave

### Weekly режим
- Используется для **закрытых недель** (предыдущая неделя)
- Загружает полную неделю (Пн–Вс) одним запросом
- Выполняется только в **понедельник или вторник** после закрытия недели
- Использует отдельный checkpoint (`sales_weekly`) для отслеживания прогресса
- Заменяет (UPSERT) любые существующие daily данные за эту неделю

### Почему нужен weekly refresh?

1. **API коррекции**: Wildberries может корректировать данные за закрытую неделю
2. **Поздние данные**: Некоторые транзакции могут появиться с задержкой
3. **Точность**: Weekly отчёт содержит финальные данные за неделю

### Backfill для sales

Backfill для sales имеет специальную логику:
- Загружает историю **назад** по полным неделям (Пн–Вс)
- Начинает с последней закрытой недели (не текущей)
- Движется назад до `backfillLowerBound` ('2024-01-29')
- Использует `syncMode: 'weekly'` для загрузки полных недель
- Использует отдельный checkpoint (`sales_backfill`) для отслеживания прогресса
